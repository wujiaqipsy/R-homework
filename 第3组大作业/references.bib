@article{anderson2011,
  title = {Value-Driven Attentional Capture},
  author = {Anderson, Brian A. and Laurent, Patryk A. and Yantis, Steven},
  year = {2011},
  month = jun,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {108},
  number = {25},
  pages = {10367--10371},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1104047108},
  urldate = {2024-06-16},
  abstract = {Attention selects which aspects of sensory input are brought to awareness. To promote survival and well-being, attention prioritizes stimuli both voluntarily, according to context-specific goals (e.g., searching for car keys), and involuntarily, through attentional capture driven by physical salience (e.g., looking toward a sudden noise). Valuable stimuli strongly modulate voluntary attention allocation, but there is little evidence that high-value but contextually irrelevant stimuli capture attention as a consequence of reward learning. Here we show that visual search for a salient target is slowed by the presence of an inconspicuous, task-irrelevant item that was previously associated with monetary reward during a brief training session. Thus, arbitrary and otherwise neutral stimuli imbued with value via associative learning capture attention powerfully and persistently during extinction, independently of goals and salience. Vulnerability to such value-driven attentional capture covaries across individuals with working memory capacity and trait impulsivity. This unique form of attentional capture may provide a useful model for investigating failures of cognitive control in clinical syndromes in which value assigned to stimuli conflicts with behavioral goals (e.g., addiction, obesity).},
  langid = {english},
  keywords = {/unread},
  file = {C:\Users\25453\Zotero\storage\NN3R3232\Anderson 等 - 2011 - Value-driven attentional capture.pdf}
}

@article{golubickis2021,
  title = {Valence and Ownership: Object Desirability Influences Self-Prioritization},
  shorttitle = {Valence and Ownership},
  author = {Golubickis, Marius and Ho, Nerissa S. P. and Falb{\'e}n, Johanna K. and Schwertel, Carlotta L. and Maiuri, Alessia and Dublas, Dagmara and Cunningham, William A. and Macrae, C. Neil},
  year = {2021},
  month = feb,
  journal = {Psychological Research},
  volume = {85},
  number = {1},
  pages = {91--100},
  issn = {1430-2772},
  doi = {10.1007/s00426-019-01235-w},
  urldate = {2024-06-16},
  abstract = {Research has demonstrated that possession exerts a potent influence on stimulus processing, such that objects are categorized more rapidly when owned-by-self than when they belong to other people. Outstanding theoretical questions remain, however, regarding the extent of this self-prioritization effect. In particular, does ownership enhance the processing of objects regardless of their valence or is self-prioritization restricted to only desirable items? To address this issue, here we explored the speed with which participants categorized objects (i.e., desirable and undesirable posters) that ostensibly belonged to the self and a best friend. In addition, to identify the cognitive processes supporting task performance, data were submitted to a hierarchical drift-diffusion model (HDDM) analysis. The results revealed a self-prioritization effect (i.e., RTself\,{$<$}\,RTfriend) for desirable posters that was underpinned by differences in the efficiency of stimulus processing. Specifically, decisional evidence was extracted more rapidly from self-owned posters when they were desirable than undesirable, an effect that was reversed for friend-owned posters. These findings advance understanding of when and how valence influences self-prioritization during decisional processing.},
  langid = {english},
  keywords = {/unread},
  file = {D:\Application_tool\Zotero数据库\Psychological Research2021\Golubickis et al_2021_Valence and ownership.pdf}
}

@article{hugdahl1993,
  title = {Laterality for {{Facial Expressions}}: {{Does}} the {{Sex}} of the {{Subject Interact}} with the {{Sex}} of the {{Stimulus Face}}?},
  shorttitle = {Laterality for {{Facial Expressions}}},
  author = {Hugdahl, Kenneth and Iversen, P{\aa}l Mo and Johnsen, Bj{\o}rn Helge},
  year = {1993},
  month = jun,
  journal = {Cortex},
  volume = {29},
  number = {2},
  pages = {325--331},
  issn = {00109452},
  doi = {10.1016/S0010-9452(13)80185-2},
  urldate = {2024-06-16},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english},
  keywords = {/unread},
  file = {C:\Users\25453\Zotero\storage\QV8JL6LC\Hugdahl 等 - 1993 - Laterality for Facial Expressions Does the Sex of.pdf}
}

@article{moray1959,
  title = {Attention in {{Dichotic Listening}}: {{Affective Cues}} and the {{Influence}} of {{Instructions}}},
  shorttitle = {Attention in {{Dichotic Listening}}},
  author = {Moray, Neville},
  year = {1959},
  month = feb,
  journal = {Quarterly Journal of Experimental Psychology},
  volume = {11},
  number = {1},
  pages = {56--60},
  issn = {0033-555X},
  doi = {10.1080/17470215908416289},
  urldate = {2024-06-16},
  abstract = {In shadowing one of two simultaneous messages presented dichotically, subjects are unable to report any of the content of the rejected message. Even if the rejected message consists of a short list of simple words repeated many times, a recognition test fails to reveal any trace of the list. If numbers are interpolated in prose passages presented for dichotic shadowing, no more are recalled from the rejected messages if the instructions are specifically to remember numbers than if the instructions are general: a specific set for numbers will not break through the attentional barrier set up in this task. The only stimulus so far found that will break through this barrier is the subject's own name. It is probably only material ``important'' to the subject that will break through the barrier.},
  copyright = {http://journals.sagepub.com/page/policies/text-and-data-mining-license},
  langid = {english},
  keywords = {/unread},
  file = {C\:\\Users\\25453\\Zotero\\storage\\94VW8BQQ\\Moray - 1959 - Attention in Dichotic Listening Affective Cues an.pdf;C\:\\Users\\25453\\Zotero\\storage\\BQA42R2S\\Tong, F., & Nakayama, K. (1999). Robust representations for faces Evidence from visual.pdf;C\:\\Users\\25453\\Zotero\\storage\\ZTQIBWHA\\Golubickis, M., Ho, N. S. P., Falb´en, J. K., et al. (2021). Valence and ownership Object.pdf}
}

@article{stenberg1998,
  title = {Judging {{Words}} at {{Face Value}}: {{Interference}} in a {{Word Processing Task Reveals Automatic Processing}} of {{Affective Facial Expressions}}},
  shorttitle = {Judging {{Words}} at {{Face Value}}},
  author = {Stenberg, Georg and Wiking, Susanne and Dahl, Mats},
  year = {1998},
  month = nov,
  journal = {Cognition \& Emotion},
  volume = {12},
  number = {6},
  pages = {755--782},
  issn = {0269-9931, 1464-0600},
  doi = {10.1080/026999398379420},
  urldate = {2024-06-16},
  langid = {english},
  keywords = {/unread},
  file = {C\:\\Users\\25453\\Zotero\\storage\\GW8QMB93\\Stenberg 等 - 1998 - Judging Words at Face Value Interference in a Wor.pdf;D\:\\A硕士\\libraries\\R_REFERENCE\\Golubickis, M., Ho, N. S. P., Falb´en, J. K., et al. (2021). Valence and ownership Object.pdf}
}

@article{sui2013,
  title = {The Boundaries of Self Face Perception: {{Response}} Time Distributions, Perceptual Categories, and Decision Weighting},
  shorttitle = {The Boundaries of Self Face Perception},
  author = {Sui, Jie and Humphreys, Glyn W.},
  year = {2013},
  month = apr,
  journal = {Visual Cognition},
  volume = {21},
  number = {4},
  pages = {415--445},
  issn = {1350-6285, 1464-0716},
  doi = {10.1080/13506285.2013.800621},
  urldate = {2024-06-16},
  langid = {english},
  keywords = {/unread}
}

@article{sui2015,
  title = {More of Me! {{Distinguishing}} Self and Reward Bias Using Redundancy Gains},
  author = {Sui, Jie and Humphreys, Glyn W.},
  year = {2015},
  month = nov,
  journal = {Attention, Perception, \& Psychophysics},
  volume = {77},
  number = {8},
  pages = {2549--2561},
  issn = {1943-3921, 1943-393X},
  doi = {10.3758/s13414-015-0970-x},
  urldate = {2024-06-16},
  abstract = {Participants show a perceptual bias favoring stimuli associated with the participants themselves over stimuli associated with other people. A major account of this self-bias effect is that self-related information is intrinsically rewarding, and that high-reward stimuli have enhanced perceptual processing. Here we used redundancy gains to examine the relations between self bias and reward, and whether self and reward biases modulate common levels of stimulus integration. We demonstrated that the self-association bias increases when more than one exemplar of the stimulus is presented (i.e., when participants are exposed to redundant stimuli). The larger self-bias effects for redundant than for single stimuli arose at both perceptual and conceptual levels of representation (respectively, for identical and nonidentical stimuli associated with the same category). In contrast, high-reward stimuli did not affect perceptual redundancy gains with identical shapes, but they did affect redundancy gains with nonidentical stimuli associated with the same category. The strong redundancy effects with self-related stimuli are consistent with self associations modulating stimulus integration at both perceptual and conceptual levels, whereas reward only modulated higher-level conceptual processes (with nonidentical stimuli).},
  langid = {english},
  keywords = {/unread},
  file = {C\:\\Users\\25453\\Zotero\\storage\\LSDUIAC7\\Sui 和 Humphreys - 2015 - More of me! Distinguishing self and reward bias us.pdf;D\:\\Application_tool\\Zotero数据库\\Attention, Perception, & Psychophysics2015\\Sui_Humphreys_2015_More of me.pdf}
}

@article{tong1999,
  title = {Robust Representations for Faces: {{Evidence}} from Visual Search.},
  shorttitle = {Robust Representations for Faces},
  author = {Tong, Frank and Nakayama, Ken},
  year = {1999},
  journal = {Journal of Experimental Psychology: Human Perception and Performance},
  volume = {25},
  number = {4},
  pages = {1016--1035},
  issn = {1939-1277, 0096-1523},
  doi = {10.1037/0096-1523.25.4.1016},
  urldate = {2024-06-16},
  langid = {english},
  keywords = {/unread}
}

@article{turk2011,
  title = {When ``{{It}}'' {{Becomes}} ``{{Mine}}'': {{Attentional Biases Triggered}} by {{Object Ownership}}},
  shorttitle = {When ``{{It}}'' {{Becomes}} ``{{Mine}}''},
  author = {Turk, David J. and Van Bussel, Kim and Brebner, Joanne L. and Toma, Andreea S. and Krigolson, Olav and Handy, Todd C.},
  year = {2011},
  month = dec,
  journal = {Journal of Cognitive Neuroscience},
  volume = {23},
  number = {12},
  pages = {3725--3733},
  issn = {0898-929X, 1530-8898},
  doi = {10.1162/jocn_a_00101},
  urldate = {2024-06-16},
  abstract = {Abstract             Previous research has demonstrated that higher-order cognitive processes associated with the allocation of selective attention are engaged when highly familiar self-relevant items are encountered, such as one's name, face, personal possessions and the like. The goal of our study was to determine whether these effects on attentional processing are triggered on-line at the moment self-relevance is established. In a pair of experiments, we recorded ERPs as participants viewed common objects (e.g., apple, socks, and ketchup) in the context of an ``ownership'' paradigm, where the presentation of each object was followed by a cue indicating whether the object nominally belonged either to the participant (a ``self'' cue) or the experimenter (an ``other'' cue). In Experiment 1, we found that ``self'' ownership cues were associated with increased attentional processing, as measured via the P300 component. In Experiment 2, we replicated this effect while demonstrating that at a visual--perceptual level, spatial attention became more narrowly focused on objects owned by self, as measured via the lateral occipital P1 ERP component. Taken together, our findings indicate that self-relevant attention effects are triggered by the act of taking ownership of objects associated with both perceptual and postperceptual processing in cortex.},
  langid = {english},
  keywords = {/unread},
  file = {C\:\\Users\\25453\\Zotero\\storage\\5KPF32DS\\Turk 等 - 2011 - When “It” Becomes “Mine” Attentional Biases Trigg.pdf;C\:\\Users\\25453\\Zotero\\storage\\76Y6ME9Q\\Golubickis, M., Ho, N. S. P., Falb´en, J. K., et al. (2021). Valence and ownership Object.pdf;C\:\\Users\\25453\\Zotero\\storage\\97UAYFK7\\Golubickis, M., Ho, N. S. P., Falb´en, J. K., et al. (2021). Valence and ownership Object.pdf;C\:\\Users\\25453\\Zotero\\storage\\EM7D6L8S\\Golubickis, M., Ho, N. S. P., Falb´en, J. K., et al. (2021). Valence and ownership Object.pdf;C\:\\Users\\25453\\Zotero\\storage\\I6G6APM2\\Golubickis, M., Ho, N. S. P., Falb´en, J. K., et al. (2022). Valence and ownership Object.pdf;C\:\\Users\\25453\\Zotero\\storage\\MPF3VIPZ\\Golubickis, M., Ho, N. S. P., Falb´en, J. K., et al. (2021). Valence and ownership Object.pdf;C\:\\Users\\25453\\Zotero\\storage\\RLQYTFK5\\Golubickis, M., Ho, N. S. P., Falb´en, J. K., et al. (2022). Valence and ownership Object.pdf;C\:\\Users\\25453\\Zotero\\storage\\ULGHIQSW\\Golubickis, M., Ho, N. S. P., Falb´en, J. K., et al. (2021). Valence and ownership Object.pdf;C\:\\Users\\25453\\Zotero\\storage\\VVV85FKA\\Golubickis, M., Ho, N. S. P., Falb´en, J. K., et al. (2022). Valence and ownership Object.pdf;D\:\\Application_tool\\Zotero数据库\\Journal of Cognitive Neuroscience2011\\Turk et al_2011_When “It” Becomes “Mine”.pdf;D\:\\Application_tool\\Zotero数据库\\Journal of Cognitive Neuroscience2011\\Turk et al_2011_When “It” Becomes “Mine”2.pdf}
}

@article{sui2012,
	title = {Perceptual effects of social salience: Evidence from self-prioritization effects on perceptual matching},
	author = {Sui, Jie and He, Xun and Humphreys, Glyn W.},
	year = {2012},
	date = {2012},
	journal = {Journal of Experimental Psychology: Human Perception and Performance},
	pages = {1105--1117},
	volume = {38},
	number = {5},
	doi = {10.1037/a0029792},
	note = {SC: NoData[s0] 
Place: US
Publisher: American Psychological Association
Citation Key: sui2012}
}
